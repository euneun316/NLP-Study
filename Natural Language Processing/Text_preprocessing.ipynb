{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPg95+Y8rIgh9qZ4Lj2eNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euneun316/NLP-Study/blob/main/Natural%20Language%20Processing/Text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02.텍스트 전처리(Text preprocessing)\n",
        "- 풀고자 하는 문제의 용도에 맞게 텍스트를 사전에 처리하는 작업\n",
        "- 참조 Url : https://github.com/ukairia777/tensorflow-nlp-tutorial"
      ],
      "metadata": {
        "id": "GRzw_LZl5Vwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01) 토큰화(Tokenization)"
      ],
      "metadata": {
        "id": "shoCHgaGAXip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 합니다."
      ],
      "metadata": {
        "id": "oVcqYKDC1Tv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.단어 토큰화(Word Tokenization)\n",
        "- NLTK는 영어 코퍼스를 토큰화하기 위한 도구들을 제공\n",
        "- word_tokenize"
      ],
      "metadata": {
        "id": "83z1SE_j-hhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "se6WFb5o7uZ7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5td_xf7w9327",
        "outputId": "ea115332-414d-4108-fc9c-ed5afd4e8e31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gMGxHtf9waH",
        "outputId": "296e922c-0c80-4f2a-c13d-aa41ad2958ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- wordPunctTokenizer"
      ],
      "metadata": {
        "id": "MLflZzsK-Z3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPQgsy7--Mx4",
        "outputId": "d2ec8538-fc85-4777-fc0f-a5c4e7a52c06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 케라스"
      ],
      "metadata": {
        "id": "ezfLaC3S-U1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3t6FJ_q-Sls",
        "outputId": "659496aa-32f2-4999-8d07-e2f9de9054fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.표준 토큰화 예제\n",
        "- Penn Treebank *Tokenization*"
      ],
      "metadata": {
        "id": "hsx9zCT4_M_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhDdhGJt_HF0",
        "outputId": "7f1eb83b-e6cd-4a70-97c5-ca575d4b065f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.문장 토큰화(Sentence Tokenization)"
      ],
      "metadata": {
        "id": "tsIVuPXR1biE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLTK에서는 영어 문장의 토큰화를 수행하는 : sent_tokenize"
      ],
      "metadata": {
        "id": "CViVyl5r_fW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print('문장 토큰화1 :',sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKlHywOv_kU5",
        "outputId": "a3bec875-3474-4d7e-c4b2-4d73e0db6903"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장 중간에 마침표가 다수 등장"
      ],
      "metadata": {
        "id": "F_b9TQv5_pG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print('문장 토큰화2 :',sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVmTB6kC_rNe",
        "outputId": "92a8a45e-8727-4376-e689-8fcf9ba21004"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 박상길님이 개발한 KSS(Korean Sentence Splitter)"
      ],
      "metadata": {
        "id": "C75QUDd3_4RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efgoeOKj_uoz",
        "outputId": "f6e4befd-9680-46a4-83d3-60f68d06aa99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kss\n",
            "  Downloading kss-3.4.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 12.0 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2019.12.20)\n",
            "Building wheels for collected packages: kss, emoji\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4-py3-none-any.whl size=42449209 sha256=e7fe29bb0ba38b0593943e5e0ad5458f62a9da0035afe2c5546f9238f60d6811\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/8e/5b/305f0a804fba3943f353f1b0e3cb1fad39e4f5ae4893ea9590\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=bb7f6d70bdfeab9d42310655c4da835adf2118f6cf2e07a359e775c7a8764a19\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built kss emoji\n",
            "Installing collected packages: emoji, kss\n",
            "Successfully installed emoji-1.6.3 kss-3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
        "print('한국어 문장 토큰화 :',kss.split_sentences(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x0MHBf6_zur",
        "outputId": "5f8f2943-1096-4f17-dba7-82115438a5fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Korean Sentence Splitter]: Initializing Pynori...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.NLTK와 KoNLPy를 이용한 영어, 한국어 토큰화 실습"
      ],
      "metadata": {
        "id": "K1UA4fYlANRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLTK"
      ],
      "metadata": {
        "id": "mPORpfWqBHeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brW6VInjAvw-",
        "outputId": "c7fee608-7419-4586-d389-e1342dc52a85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print('단어 토큰화 :',tokenized_sentence)\n",
        "print('품사 태깅 :',pos_tag(tokenized_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I7wXuZlAr0h",
        "outputId": "52cf1789-0837-4b79-a61a-1b111caca932"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
            "품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Okt"
      ],
      "metadata": {
        "id": "-CuaBQSaA1vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E3J71JzA7IJ",
        "outputId": "b2a0fcd0-b3ea-4a74-94b5-f0de39a982de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()\n",
        "\n",
        "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8lZvoiCA6PN",
        "outputId": "56215bd3-909a-43d0-a11e-b56b5ca20753"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
            "OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n",
            "OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 꼬꼬마"
      ],
      "metadata": {
        "id": "Hdjx-sPfBN0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('꼬꼬마 형태소 분석 :',kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('꼬꼬마 품사 태깅 :',kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('꼬꼬마 명사 추출 :',kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCfLw8LGBU_A",
        "outputId": "355a0ca5-87fa-4800-d954-6aeeae70f238"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "꼬꼬마 형태소 분석 : ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n",
            "꼬꼬마 품사 태깅 : [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n",
            "꼬꼬마 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02) 정제(Cleaning) and 정규화(Normalization)"
      ],
      "metadata": {
        "id": "KfmF_UI4B3C9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 영어는 길이가 2~3 이하인 단어를 제거하는 것만으로도 크게 의미를 갖지 못하는 단어를 줄이는 효과를 갖고있습니다."
      ],
      "metadata": {
        "id": "xtRWOW16C5pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
        "\n",
        "# 길이가 1~2인 단어들을 정규 표현식을 이용하여 삭제\n",
        "shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('', text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9UpvKV6B6Lt",
        "outputId": "f036f15a-90ba-4b21-f23f-a7934b3ba737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " was wondering anyone out there could enlighten this car.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03) 어간 추출(Stemming) and 표제어 추출(Lemmatization)"
      ],
      "metadata": {
        "id": "TYaelMhVCM3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "눈으로 봤을 때는 서로 다른 단어들이지만, 하나의 단어로 일반화시킬 수 있다면 하나의 단어로 일반화시켜서 문서 내의 단어 수를 줄이겠다는 것"
      ],
      "metadata": {
        "id": "V-Wr0end134L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.표제어 추출(Lemmatization)"
      ],
      "metadata": {
        "id": "UOCZ3SF1ELCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미"
      ],
      "metadata": {
        "id": "GmnJuaVh17QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Pb2vlzEF_S",
        "outputId": "d01a3dbb-d8ca-407f-de61-c99e84316bbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('표제어 추출 전 :',words)\n",
        "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0606hDbiEELz",
        "outputId": "31c1fe89-7576-4ba9-f974-a8c33cfd54c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- WordNetLemmatizer"
      ],
      "metadata": {
        "id": "jxWJdTR3Eb7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('dies', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h5ud8DewEXQ1",
        "outputId": "f23798ce-d5d5-4988-f5c9-b07c2190e72a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'die'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('watched', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vCnHRnxrEejk",
        "outputId": "23cbb649-f003-4fa6-a120-45cf403d1b62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'watch'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('has', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wR3aPYOqEgQm",
        "outputId": "ab7c7087-b524-4a5a-cfd3-4d3a7989d0d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'have'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.어간 추출(Stemming)"
      ],
      "metadata": {
        "id": "QSjuUWMvEiRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "어간 추출은 형태학적 분석을 단순화한 버전이라고 볼 수도 있고, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업"
      ],
      "metadata": {
        "id": "SVArjPb-2Bpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 포터 알고리즘(Porter Algorithm)"
      ],
      "metadata": {
        "id": "6K5FrSLNFgwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "tokenized_sentence = word_tokenize(sentence)\n",
        "\n",
        "print('어간 추출 전 :', tokenized_sentence)\n",
        "print('어간 추출 후 :',[stemmer.stem(word) for word in tokenized_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYZzMmxIFYFe",
        "outputId": "d46852e1-2fe7-478a-cf88-d20aee083d8b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
            "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['formalize', 'allowance', 'electricical']\n",
        "\n",
        "print('어간 추출 전 :',words)\n",
        "print('어간 추출 후 :',[stemmer.stem(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZ63_A7FcKN",
        "outputId": "95926079-71f4-47b7-cc65-81f5c0d9a129"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['formalize', 'allowance', 'electricical']\n",
            "어간 추출 후 : ['formal', 'allow', 'electric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLTK에서는 포터 알고리즘 외에도 랭커스터 스태머(Lancaster Stemmer) 알고리즘을 지원"
      ],
      "metadata": {
        "id": "t_Xew6KnFoDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print('어간 추출 전 :', words)\n",
        "print('포터 스테머의 어간 추출 후:',[porter_stemmer.stem(w) for w in words])\n",
        "print('랭커스터 스테머의 어간 추출 후:',[lancaster_stemmer.stem(w) for w in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acLUZvNeGFWk",
        "outputId": "f29b3f02-6052-46f6-93da-6aad6643b284"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "포터 스테머의 어간 추출 후: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
            "랭커스터 스테머의 어간 추출 후: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.한국어에서의 어간 추출"
      ],
      "metadata": {
        "id": "kudEfi2jGOVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04) 불용어(Stopword)"
      ],
      "metadata": {
        "id": "orKsrV8bHiA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업이 필요"
      ],
      "metadata": {
        "id": "HzDUhMvl1yoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "fWs9-zONHjwX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.NLTK에서 불용어 확인하기"
      ],
      "metadata": {
        "id": "5USgMVK7HwD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P6UFPnSHzsU",
        "outputId": "8da1ae82-259d-4838-c21f-478cd7273aa3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_list = stopwords.words('english')\n",
        "print('불용어 개수 :', len(stop_words_list))\n",
        "print('불용어 10개 출력 :',stop_words_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ya0wd4HxLC",
        "outputId": "6f8785b2-2355-41b1-d01e-4ae49b74403b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수 : 179\n",
            "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.NLTK를 통해서 불용어 제거하기"
      ],
      "metadata": {
        "id": "pgzxEwLdH5fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "word_tokens = word_tokenize(example)\n",
        "\n",
        "result = []\n",
        "for word in word_tokens: \n",
        "    if word not in stop_words: \n",
        "        result.append(word) \n",
        "\n",
        "print('불용어 제거 전 :',word_tokens) \n",
        "print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-B5yMHEH6M5",
        "outputId": "52c64d0e-706b-4f62-e6ef-3ec9daaada1b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.한국어에서 불용어 제거하기"
      ],
      "metadata": {
        "id": "cGeBAQIQICsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
        "\n",
        "stop_words = set(stop_words.split(' '))\n",
        "word_tokens = okt.morphs(example)\n",
        "\n",
        "result = [word for word in word_tokens if not word in stop_words]\n",
        "\n",
        "print('불용어 제거 전 :',word_tokens) \n",
        "print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5rr1MZWIDxz",
        "outputId": "c2ba3e31-fe6a-46a2-e744-9c651f6e4f4d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
            "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05) 정규 표현식(Regular Expression)"
      ],
      "metadata": {
        "id": "vT3S2zN3IbuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "xB0nxL1lIn-0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) .기호"
      ],
      "metadata": {
        "id": "2HCXsbi_I2vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"a.c\")\n",
        "r.search(\"kkk\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "A-ghdvNrIpji"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncTIDyD0Ivu3",
        "outputId": "4d905710-706c-4187-dbfe-61f525c95cdf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) ?기호"
      ],
      "metadata": {
        "id": "1Sqhpy8VI6gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab?c\")\n",
        "r.search(\"abbc\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "0dv3PCoyIy9d"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqbgKPK7JB9q",
        "outputId": "069bc8ef-efd0-48f5-bc61-6edbd5ee1d1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdlmfVqBJGLh",
        "outputId": "33c574a8-e761-4861-be42-9dd82ca03133"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) *기호"
      ],
      "metadata": {
        "id": "SXQkwt83JJIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab*c\")\n",
        "r.search(\"a\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "esacixDvJQaW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ac\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrcjSOQHJSWq",
        "outputId": "7fe46234-fa6b-4d94-8dcb-30fe00edd2a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEBz48h-JUTl",
        "outputId": "bf7dfc33-2a44-4e08-98ce-136c6191483a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbbc\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zGjitM4JVtl",
        "outputId": "590e55e8-2ef6-4567-f05a-42ce8b9b3988"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) +기호"
      ],
      "metadata": {
        "id": "_0_gAfU9JXRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab+c\")\n",
        "r.search(\"ac\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "khrV4fVcJcDs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBySeBFNJdy8",
        "outputId": "2254a97f-8117-4b5a-8029-fdc2d7dab02b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbbc\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxmyL876JfLG",
        "outputId": "6c938dbf-fd06-4cdd-8571-74520126d992"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) ^기호"
      ],
      "metadata": {
        "id": "k4fPlUb5Jg2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"^ab\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"bbc\")\n",
        "r.search(\"zab\")"
      ],
      "metadata": {
        "id": "uZgU7VtGJl24"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6msQ4MXcJoBm",
        "outputId": "5cf5411e-8d06-4267-c7ca-a14900f3fbc4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ab'>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) {숫자} 기호"
      ],
      "metadata": {
        "id": "iHb9gMUvJp4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2}c\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbbc\")"
      ],
      "metadata": {
        "id": "oT0F-GAJJvm6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFms3kdeJyPG",
        "outputId": "c74a6b4f-d03b-475c-ff75-758a4ef08489"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) {숫자1, 숫자2} 기호"
      ],
      "metadata": {
        "id": "sjk7fWXoJ0Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2,8}c\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"ac\")\n",
        "r.search(\"abc\")\n",
        "r.search(\"abbbbbbbbbc\")"
      ],
      "metadata": {
        "id": "FuXXJBKPJ673"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rpOgZhQJ-lr",
        "outputId": "67e2251e-6d91-4738-e494-7f6a54c1a395"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbbbbbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc2kmUW-J_2j",
        "outputId": "ec5f5d63-5c13-426e-a975-15184691e303"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) {숫자,} 기호"
      ],
      "metadata": {
        "id": "R0ROFecPKBeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"a{2,}bc\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"bc\")\n",
        "r.search(\"aa\")"
      ],
      "metadata": {
        "id": "xbG3qe2ZKImk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"aabc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF34kWGoKN6C",
        "outputId": "ca499b16-3da0-485e-f85f-94ced85f6a8b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='aabc'>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"aaaaaaaabc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vGvr8oWKQZa",
        "outputId": "562e5614-6f03-4ea1-87c2-3ce9c0528650"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='aaaaaaaabc'>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) [ ] 기호"
      ],
      "metadata": {
        "id": "dDIKZRnrKR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[abc]\") # [abc]는 [a-c]와 같다.\n",
        "r.search(\"zzz\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "Z0AE-dcfKX99"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe9rcYDJKZcL",
        "outputId": "dc176a23-c914-4e2f-f1b5-462a20581183"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"aaaaaaa\")          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlm7D6RQKb4X",
        "outputId": "0d359b52-d9b6-41df-e299-57c091122e46"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"baac\")     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcWkGbCLKdE-",
        "outputId": "a541b07c-0433-4813-8350-d1c9407a01da"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='b'>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[a-z]\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"AAA\")\n",
        "r.search(\"111\") "
      ],
      "metadata": {
        "id": "fL4FSugrKep8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"aBC\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1cw8gKAKf9T",
        "outputId": "ee889a4d-624d-4f8e-d49c-dcff33b77936"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) [^문자] 기호"
      ],
      "metadata": {
        "id": "dB_eIS5zKhe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[^abc]\")\n",
        "\n",
        "# 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"a\")\n",
        "r.search(\"ab\") \n",
        "r.search(\"b\")"
      ],
      "metadata": {
        "id": "neFZV7YUKmrU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFy326iaKoMy",
        "outputId": "eca7f486-721e-439b-9ff6-0c2b5e8fa95b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='d'>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"1\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgDxzBucKpv2",
        "outputId": "9ed4ddce-d2de-46a5-f318-0e3bd1d6a5b0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='1'>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.정규 표현식 모듈 함수 예제"
      ],
      "metadata": {
        "id": "IJ8YXS97KriF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) re.match() 와 re.search()의 차이"
      ],
      "metadata": {
        "id": "j0Opb3dQK936"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab.\")\n",
        "r.match(\"kkkabc\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "ueZYrxmlKsue"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"kkkabc\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdoNI5N0K5MB",
        "outputId": "d4ab8ef6-2935-40bd-a99c-64ccdbaf2f85"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(3, 6), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.match(\"abckkk\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3et8rS_QK77V",
        "outputId": "de5a5e48-b2dd-41cf-d734-4e5a5252668f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) re.split()"
      ],
      "metadata": {
        "id": "mnDfrlGtLBqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 공백 기준 분리\n",
        "text = \"사과 딸기 수박 메론 바나나\"\n",
        "re.split(\" \", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgeITzXOLFe2",
        "outputId": "6a1a54df-9ca9-429f-9d40-89f7410588cf"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 줄바꿈 기준 분리\n",
        "text = \"\"\"사과\n",
        "딸기\n",
        "수박\n",
        "메론\n",
        "바나나\"\"\"\n",
        "\n",
        "re.split(\"\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLXTHLpsLIPd",
        "outputId": "d4d551ea-596c-417c-914d-c46fbdac6015"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '+'를 기준으로 분리\n",
        "text = \"사과+딸기+수박+메론+바나나\"\n",
        "\n",
        "re.split(\"\\+\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLi4NYXSLLtg",
        "outputId": "e06fc192-d148-472d-acd8-407a120bc016"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) re.findall()"
      ],
      "metadata": {
        "id": "tLoWbvwYLNwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "\n",
        "re.findall(\"\\d+\", text) #숫자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHdFi8CWLSZE",
        "outputId": "a2c6b849-256b-4598-ce17-898a5a68e6ab"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '1234', '1234', '30']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"\\d+\", \"문자열입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLBbFz98LZ_j",
        "outputId": "594309ed-0850-496f-ca56-8a584b53de6e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) re.sub()"
      ],
      "metadata": {
        "id": "Yohp5G0aLekC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "\n",
        "preprocessed_text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "print(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb7pQ_lcLhwu",
        "outputId": "afdf5953-86bc-49dd-bdd8-4d47e315d028"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.정규 표현식 텍스트 전처리 예제"
      ],
      "metadata": {
        "id": "UGiaooi2LuHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"100 John    PROF\n",
        "101 James   STUD\n",
        "102 Mac   STUD\"\"\""
      ],
      "metadata": {
        "id": "ytusGjjgLwPn"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s+', text)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ndjq_WLy-z",
        "outputId": "13efde37-79fc-4b5b-b1df-daa4b5c2eafd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\d+',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcBVabqL2q2",
        "outputId": "96542002-202d-45e9-a00b-79c1b19c0aca"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj9IJV3vL4la",
        "outputId": "91047a86-9f5f-40ee-9693-3948538a5e27"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]{4}',text)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALsQhBoL6MB",
        "outputId": "002d648a-b0a8-44af-c036-07a934bd40ad"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROF', 'STUD', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z][a-z]+',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU12BhjXL-BR",
        "outputId": "4d7f1239-122a-4534-f403-09b20aa5a7de"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'James', 'Mac']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.정규 표현식을 이용한 토큰화"
      ],
      "metadata": {
        "id": "-5TOJBteMAKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
        "\n",
        "tokenizer1 = RegexpTokenizer(\"[\\w]+\")\n",
        "tokenizer2 = RegexpTokenizer(\"\\s+\", gaps=True)\n",
        "\n",
        "print(tokenizer1.tokenize(text))\n",
        "print(tokenizer2.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G4rDPMiMNP_",
        "outputId": "172bd460-831c-406f-fb51-92674e50b94e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06) 정수 인코딩(Integer Encoding)"
      ],
      "metadata": {
        "id": "HAdOYw1xo1pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트를 숫자로 바꾸는 여러가지 기법들이 있습니다.<br>\n",
        "각 단어를 고유한 정수에 맵핑(mapping)시키는 전처리 작업이 필요할 때가 있습니다."
      ],
      "metadata": {
        "id": "djwQ3JW7wSpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.정수 인코딩(Integer Encoding)"
      ],
      "metadata": {
        "id": "P7c3mO6r3E8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어에 정수를 부여하는 방법 중 하나로 단어를 빈도수 순으로 정렬한 단어 집합(vocabulary)을 만들고, 빈도수가 높은 순서대로 차례로 낮은 숫자부터 정수를 부여하는 방법이 있습니다."
      ],
      "metadata": {
        "id": "WOxYGYbX3IQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 dictionary 사용하기"
      ],
      "metadata": {
        "id": "APW0NZL75efQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "jvidcnqS5leg"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "kBLnSXg45nbV"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존의 텍스트 데이터가 문장 단위로 토큰화 됨"
      ],
      "metadata": {
        "id": "XoUXcFEe6ni5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "sentences = sent_tokenize(raw_text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6UoUdyz5psQ",
        "outputId": "0079b580-abd8-4544-dab2-aa2f64906d9c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어가 텍스트일 때만 할 수 있는 최대한의 전처리를 끝내놓아야 합니다."
      ],
      "metadata": {
        "id": "AXdveG676zbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "# stop_words 셋팅\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "    # 단어 토큰화\n",
        "    tokenized_sentence = word_tokenize(sentence)\n",
        "    result = []\n",
        "\n",
        "    for word in tokenized_sentence: \n",
        "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄인다.\n",
        "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거한다.\n",
        "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거한다.\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0 \n",
        "                vocab[word] += 1\n",
        "    preprocessed_sentences.append(result) \n",
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfRprQUi6sDh",
        "outputId": "8c8e715b-e4b8-45d6-813c-57019acd4453"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 단어에 대한 빈도수가 기록\n",
        "print('단어 집합 :',vocab)\n",
        "# 단어를 키(key)로, 단어에 대한 빈도수가 값(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuS_z6hJ8JmZ",
        "outputId": "fe18f982-65d3-4741-97c8-7fb5d63196dd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'barber'라는 단어의 빈도수 출력\n",
        "print(vocab[\"barber\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS_B4_Fa9B8s",
        "outputId": "6aba2556-ece9-4aed-e434-f690d36bc627"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#빈도수가 높은 순서대로 정렬\n",
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie0APsxb9EUl",
        "outputId": "fb2435a6-113e-4d2d-c46a-38dfb51b5823"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 높은 빈도수를 가진 단어일수록 낮은 정수를 부여한다. 정수는 1부터 부여\n",
        "- 등장 빈도가 낮은 단어는 자연어 처리에서 의미를 가지지 않을 가능성이 높다.\n",
        "- 여기서는 빈도수가 1인 단어들은 전부 제외"
      ],
      "metadata": {
        "id": "SL09av3f9fP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab_sorted :\n",
        "    if frequency > 1 : # 빈도수가 작은 단어는 제외.\n",
        "        i = i + 1\n",
        "        word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAHdgUQA9aOK",
        "outputId": "7d044396-010b-4662-b481-cd744254d897"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#상위 5개 단어만 사용한다고 가정\n",
        "vocab_size = 5\n",
        "\n",
        "# 인덱스가 5 초과인 단어 제거\n",
        "words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "# 해당 단어에 대한 인덱스 정보를 삭제\n",
        "for w in words_frequency:\n",
        "    del word_to_index[w]\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgUjQ7s_-o8A",
        "outputId": "23a61790-ba2c-4f03-e4e9-a686625fb048"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. 첫번째 문장은 ['barber', 'person'] => [1, 5]로 인코딩 <br>\n",
        " 2. 두번째 문장인 ['barber', 'good', 'person'] => word_to_index에는 존재하지 않는 단어인 'good'이라는 단어가 있다. <br>\n",
        "\n",
        "- **Out-Of-Vocabulary** : 단어 집합에 존재하지 않는 단어들이 생기는 상황을 Out-Of-Vocabulary(단어 집합에 없는 단어) 문제"
      ],
      "metadata": {
        "id": "QnFea6Fj_FFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'OOV': 6 단어 집합에 없는 단어들은 'OOV'의 인덱스로 인코딩\n",
        "word_to_index['OOV'] = len(word_to_index) + 1\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6HlN9OO-w-r",
        "outputId": "1307b7eb-4649-4ed1-e26f-5070db34916b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences = []\n",
        "for sentence in preprocessed_sentences:\n",
        "    encoded_sentence = []\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            # 단어 집합에 있는 단어라면 해당 단어의 정수를 리턴.\n",
        "            encoded_sentence.append(word_to_index[word])\n",
        "        except KeyError:\n",
        "            # 만약 단어 집합에 없는 단어라면 'OOV'의 정수를 리턴.\n",
        "            encoded_sentence.append(word_to_index['OOV'])\n",
        "    encoded_sentences.append(encoded_sentence)\n",
        "print(encoded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "surgTZMl_iRF",
        "outputId": "9666b173-dd03-49dc-ca7e-86e851e1ab11"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Counter 사용하기"
      ],
      "metadata": {
        "id": "JRWEl-rm_tyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "YHe0QOffCF2U"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZsBKeXgCHRY",
        "outputId": "aa1d8a2d-4fa0-4d16-fe74-c35416a4b52b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 집합(vocabulary)을 만들기 위해서 sentences에서 문장의 경계인 [, ]를 제거하고 단어들을 하나의 리스트로 만듦"
      ],
      "metadata": {
        "id": "sQztavtLCK_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# words = np.hstack(preprocessed_sentences)으로도 수행 가능.\n",
        "all_words_list = sum(preprocessed_sentences, [])\n",
        "print(all_words_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opK00TkJCPix",
        "outputId": "3322299a-64c9-4538-99f9-ee5a59616547"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter() : 사용하면 중복을 제거하고 단어의 빈도수를 기록"
      ],
      "metadata": {
        "id": "V913kWcxD-t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬의 Counter 모듈을 이용하여 단어의 빈도수 카운트\n",
        "vocab = Counter(all_words_list)\n",
        "print(vocab)\n",
        "# 단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLGDv6AuD8US",
        "outputId": "b7119560-6498-4e9b-a8ea-fe95aa378f11"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKevQSUXEDDg",
        "outputId": "29d9f4b2-f3ec-45a1-91f1-459e958e9719"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수 상위 5개의 단어만 단어 집합으로 저장\n",
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0y5G4YvEPag",
        "outputId": "abecb69e-893b-4b67-e066-2c858d194e53"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab :\n",
        "    i = i + 1\n",
        "    word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r0YHbjZEUQ7",
        "outputId": "070ecc88-0e12-42b3-8eac-c64e80b203cc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 NLTK의 FreqDist 사용하기"
      ],
      "metadata": {
        "id": "6Vp2dduQEYZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK에서는 빈도수 계산 도구인 FreqDist()를 지원. 위에서 사용한 Counter()랑 같은 방법으로 사용"
      ],
      "metadata": {
        "id": "jzZOvs2TEeCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "owi_c2MtEgBk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.hstack으로 문장 구분을 제거\n",
        "vocab = FreqDist(np.hstack(preprocessed_sentences))\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOpZ2SSxEhPf",
        "outputId": "e5abfe59-50f6-497b-9e7c-fa23e1dc7457"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'barber': 8,\n",
              "          'crazy': 1,\n",
              "          'driving': 1,\n",
              "          'good': 1,\n",
              "          'huge': 5,\n",
              "          'keeping': 2,\n",
              "          'kept': 4,\n",
              "          'knew': 1,\n",
              "          'mountain': 1,\n",
              "          'person': 3,\n",
              "          'secret': 6,\n",
              "          'went': 1,\n",
              "          'word': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQbJGaV5EjMQ",
        "outputId": "1a97f58d-ce9d-4cda-c0db-d91c1a35e5c8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLT_ImLYExSC",
        "outputId": "93625cd2-ead4-49a1-e46d-aa79ba4abb4c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여\n",
        "# enumerate()를 사용하여 좀 더 짧은 코드로 인덱스를 부여\n",
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwkJ29JwE257",
        "outputId": "b80d7646-f37b-4601-c6f0-1e01a36c5069"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 enumerate 이해하기"
      ],
      "metadata": {
        "id": "4LrFzIDhE_XW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴"
      ],
      "metadata": {
        "id": "OC1P3c-MFDZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트의 모든 토큰에 대해서 인덱스가 순차적으로 증가되며 부여\n",
        "test_input = ['a', 'b', 'c', 'd', 'e']\n",
        "for index, value in enumerate(test_input): # 입력의 순서대로 0부터 인덱스를 부여함.\n",
        "  print(\"value : {}, index: {}\".format(value, index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSNk7b-FEEN",
        "outputId": "0cd54376-a205-49a3-e7ca-3b7fe015c830"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value : a, index: 0\n",
            "value : b, index: 1\n",
            "value : c, index: 2\n",
            "value : d, index: 3\n",
            "value : e, index: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.케라스(Keras)의 텍스트 전처리"
      ],
      "metadata": {
        "id": "rW8gx32WFUZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스(Keras)는 기본적인 전처리를 위한 도구들을 제공 <br>\n",
        "정수 인코딩을 위해서 케라스의 전처리 도구인 토크나이저를 사용"
      ],
      "metadata": {
        "id": "Zdkwb6N8FZQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "rVM_iFJcFdTT"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], \n",
        "                          ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], \n",
        "                          ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], \n",
        "                          ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "metadata": {
        "id": "y1H9klUZFeS1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩 작업\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성.\n",
        "tokenizer.fit_on_texts(preprocessed_sentences) "
      ],
      "metadata": {
        "id": "4xbHZvBhFhm-"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수가 높은 순서대로 인덱스가 부여된 것을 확인\n",
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adZ0202aF_CS",
        "outputId": "c5e94712-cf51-4086-bbf6-375973b8f379"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLN8Gd6TGBak",
        "outputId": "22811f94-402b-497d-a127-b1fd26987969"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texts_to_sequences()는 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcdXlhIfGGeW",
        "outputId": "206195ac-41be-48be-a8a1-0b248300e97d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스 토크나이저에서는 tokenizer = Tokenizer(num_words=숫자)와 같은 방법으로 빈도수가 높은 상위 몇 개의 단어만 사용하겠다고 지정할 수 있다."
      ],
      "metadata": {
        "id": "0k1uHwrqGTzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "# num_words는 숫자를 0부터 카운트\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 5개 단어만 사용\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "EX3h6C8zGMQJ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실질적으로 숫자 0에 지정된 단어가 존재하지 않는데도 케라스 토크나이저가 숫자 0까지 단어 집합의 크기로 산정하는 이유는 자연어 처리에서 패딩(padding)이라는 작업 때문"
      ],
      "metadata": {
        "id": "DGf7UTYjGkGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8i8jgziGnrD",
        "outputId": "8a7ccd4b-00eb-4b72-bf44-2524923bf6e4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vry8tAtrGq0-",
        "outputId": "1a6d6f2a-7974-4281-f7f8-26a57a4c65a7"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 적용은 texts_to_sequences를 사용할 때 적용"
      ],
      "metadata": {
        "id": "AnouaU0BGuC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV9oQSmKGx8s",
        "outputId": "ee95b0c4-fcca-43b7-81e0-99da42b4a8d3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 단어부터 5번 단어까지만 보존되고 나머지 단어들은 제거된 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "hRdKo1FwHADD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "word_index와 word_counts에서도 지정된 num_words만큼의 단어만 남기고 싶다면?"
      ],
      "metadata": {
        "id": "zb6a32K9HFPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "6U_qjV-OHKeU"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1] \n",
        "\n",
        "# 인덱스가 5 초과인 단어 제거\n",
        "for word in words_frequency:\n",
        "    del tokenizer.word_index[word] # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "    del tokenizer.word_counts[word] # 해당 단어에 대한 카운트 정보를 삭제\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWc_PKGhHLt6",
        "outputId": "dd459f20-d193-45b4-9762-34673090505b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 단어 집합에 없는 단어들은 OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용"
      ],
      "metadata": {
        "id": "5s4UcXzBHPkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)"
      ],
      "metadata": {
        "id": "55Zx559OHRD1"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(tokenizer.word_index['OOV']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eguHWQYnHTgT",
        "outputId": "8088e609-2855-4fa1-9576-7587ef26d0cc"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cB1gb8fHV0e",
        "outputId": "4aa16719-96b9-4932-b08e-b8782ec97271"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "빈도수 상위 5개의 단어는 2 ~ 6까지의 인덱스를 가졌으며, 그 외 단어 집합에 없는 'good'과 같은 단어들은 전부 'OOV'의 인덱스인 1로 인코딩 됨"
      ],
      "metadata": {
        "id": "vh8-ZkgiHYsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07) 패딩(Padding)\n"
      ],
      "metadata": {
        "id": "iHj-GZoco6_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "자연어 처리를 하다보면 각 문장(또는 문서)은 서로 길이가 다를 수 있다. <br>\n",
        "기계는 길이가 전부 동일한 문서들에 대해서는 하나의 행렬로 보고, 한꺼번에 묶어서 처리 <br>\n",
        "병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업이 필요"
      ],
      "metadata": {
        "id": "COxxP6i_QC9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Numpy로 패딩"
      ],
      "metadata": {
        "id": "_QoPP-AGRSzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "bwTOvVpdQl-t"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "metadata": {
        "id": "sw4nfqjoQ5VP"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩을 수행\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences)\n",
        "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A_x0GPGTir5",
        "outputId": "2fc79070-c7fa-485f-b561-4c3d969ecf8e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 길이가 긴 문장의 길이를 계산\n",
        "max_len = max(len(item) for item in encoded)\n",
        "print('최대 길이 :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-aRANlzToyV",
        "outputId": "fb867131-e973-42f8-f29d-4c00babaf8a0"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모든 문장의 길이를 7로 맞춰준다. \n",
        "- 이때 가상의 단어 'PAD'를 사용.\n",
        "- 이 단어는 0번 단어라고 정의"
      ],
      "metadata": {
        "id": "PBOhqktGTsWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in encoded:\n",
        "    while len(sentence) < max_len:\n",
        "        sentence.append(0)\n",
        "\n",
        "padded_np = np.array(encoded)\n",
        "padded_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KBJcyGdT2PN",
        "outputId": "8560073a-b05c-42ef-f1c5-ba8de21ea8bc"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0,  0,  0],\n",
              "       [ 3,  2,  0,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기계는 이들을 하나의 행렬로 보고, 병렬 처리를 할 수 있다. \n",
        "- 0번 단어는 사실 아무런 의미도 없는 단어이기 때문에 자연어 처리하는 과정에서 기계는 0번 단어를 무시한다.\n",
        "- 데이터에 특정 값을 채워서 데이터의 크기(shape)를 조정하는 것을 패딩(padding)이라고 한다.\n",
        "- 숫자 0을 사용하고 있다면 제로 패딩(zero padding)"
      ],
      "metadata": {
        "id": "iWiM7wHKVcI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.케라스 전처리 도구로 패딩하기"
      ],
      "metadata": {
        "id": "17E4aTBmVwMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "KyODI91vV0sz"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩\n",
        "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZrJmhJ7V407",
        "outputId": "be078135-8e33-460c-d0c1-f82fd9772676"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras의 pad_sequences\n",
        "padded = pad_sequences(encoded)\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvFKdjUpV_u3",
        "outputId": "4a88d98d-6b3d-49e1-e5a0-552909466333"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  1,  8,  5],\n",
              "       [ 0,  0,  0,  0,  1,  3,  5],\n",
              "       [ 0,  0,  0,  0,  0,  9,  2],\n",
              "       [ 0,  0,  0,  2,  4,  3,  2],\n",
              "       [ 0,  0,  0,  0,  0,  3,  2],\n",
              "       [ 0,  0,  0,  0,  1,  4,  6],\n",
              "       [ 0,  0,  0,  0,  1,  4,  6],\n",
              "       [ 0,  0,  0,  0,  1,  4,  2],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 0,  0,  0,  1, 12,  3, 13]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pad_sequences는 기본적으로 문서의 뒤에 0을 채우는 것이 아니라 앞에 0으로 채운다.\n",
        "- 뒤에 0을 채우고 싶다면 인자로 padding='post'를 바꿈"
      ],
      "metadata": {
        "id": "RA5UVj2RWZc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(encoded, padding='post')\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnLwBjcoWg_R",
        "outputId": "df32377a-c1d4-4aac-ae24-42695f7f4715"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0,  0,  0],\n",
              "       [ 3,  2,  0,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy를 이용하여 패딩을 했을 때와 결과가 동일\n",
        "(padded == padded_np).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfp_X3YTWkPq",
        "outputId": "d7253275-6665-4ab5-c4a6-5c0643690b2f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 길이에 제한을 두고 패딩할 수 있다.\n",
        "- max_len의 인자로 정수를 주면, 해당 정수로 모든 문서의 길이를 동일하게 한다."
      ],
      "metadata": {
        "id": "9-3lMc6eWrnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5보다 짧은 문서들은 0으로 패딩되고, 기존에 5보다 길었다면 데이터가 손실\n",
        "padded = pad_sequences(encoded, padding='post', maxlen=5)\n",
        "padded\n",
        "# [ 7,  7,  3,  2, 10,  1, 11] ->  [ 3,  2, 10,  1, 11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSZQcQNwWxT7",
        "outputId": "09413f55-892d-40bb-c01c-25fb1031d5a1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0],\n",
              "       [ 3,  2,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0],\n",
              "       [ 3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터가 손실될 경우에 앞의 단어가 아니라 뒤의 단어가 삭제되도록 하고싶다면 truncating이라는 인자를 사용한다.\n",
        "- truncating='post'를 사용할 경우 뒤의 단어가 삭제"
      ],
      "metadata": {
        "id": "DF9sENaaW7Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(encoded, padding='post', truncating='post', maxlen=5)\n",
        "padded\n",
        "# [ 7,  7,  3,  2, 10,  1, 11] ->  [ 7,  7,  3,  2, 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_caQ362dXAbI",
        "outputId": "6751568f-7650-421f-8504-68b14960ec54"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0],\n",
              "       [ 3,  2,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10],\n",
              "       [ 1, 12,  3, 13,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "숫자 0이 아니라 다른 숫자를 패딩을 위한 숫자로 사용하고 싶다면 이 또한 가능"
      ],
      "metadata": {
        "id": "dI3no5-2XiQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_value = len(tokenizer.word_index) + 1 # 단어 집합의 크기보다 1 큰 숫자를 사용\n",
        "print(last_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZURuD5WXppG",
        "outputId": "a267b096-fb1f-4ae4-a14b-35bfd1c3e6d2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(encoded, padding='post', value=last_value)\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_tU9uyQXuO-",
        "outputId": "9786c705-c7eb-4b1a-8b48-8fb7075a91c1"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5, 14, 14, 14, 14, 14],\n",
              "       [ 1,  8,  5, 14, 14, 14, 14],\n",
              "       [ 1,  3,  5, 14, 14, 14, 14],\n",
              "       [ 9,  2, 14, 14, 14, 14, 14],\n",
              "       [ 2,  4,  3,  2, 14, 14, 14],\n",
              "       [ 3,  2, 14, 14, 14, 14, 14],\n",
              "       [ 1,  4,  6, 14, 14, 14, 14],\n",
              "       [ 1,  4,  6, 14, 14, 14, 14],\n",
              "       [ 1,  4,  2, 14, 14, 14, 14],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13, 14, 14, 14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08) 원-핫 인코딩(One-Hot Encoding)"
      ],
      "metadata": {
        "id": "Z-KLWJlMo-TS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법이 있는데, 원-핫 인코딩(One-Hot Encoding)은 그 많은 기법 중에서 단어를 표현하는 가장 기본적인 표현 방법\n",
        "\n",
        "**단어 집합(vocabulary)**\n",
        "- 서로 다른 단어들의 집합\n",
        "- book과 books와 같이 단어의 변형 형태도 다른 단어로 간주\n",
        "- 텍스트의 모든 단어를 중복을 허용하지 않고 모아둠"
      ],
      "metadata": {
        "id": "cK505vRGmG1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.원-핫 인코딩(One-Hot Encoding)이란?"
      ],
      "metadata": {
        "id": "DfhZRWEomyOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 집합의 크기를 벡터의 차원으로 하고, <br>\n",
        "표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, <br>\n",
        "다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식 <br>\n",
        "이렇게 표현된 벡터를 _원-핫 벡터(One-Hot vector)_ 라고 한다.\n",
        "1. 정수 인코딩을 수행. 각 단어에 고유한 정수를 부여\n",
        "2. 표현하고 싶은 단어의 고유한 정수를 인덱스로 간주하고 해당 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여"
      ],
      "metadata": {
        "id": "Q23L3IAWm2jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Okt 형태소 분석기를 통해서 문장에 대해서 토큰화를 수행\n",
        "from konlpy.tag import Okt  \n",
        "\n",
        "okt = Okt()  \n",
        "tokens = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ol4vMKCnuzy",
        "outputId": "65ccba92-0431-4104-e572-ea33d0fe7e37"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 토큰에 대해서 고유한 정수를 부여\n",
        "# 빈도수 순으로 단어를 정렬하여 정수를 부여하는 경우가 많음\n",
        "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
        "print('단어 집합 :',word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjvlw0WIn0Ai",
        "outputId": "da7674f5-37b2-4513-9a28-692765c4ef37"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수\n",
        "def one_hot_encoding(word, word_to_index):\n",
        "  one_hot_vector = [0]*(len(word_to_index))\n",
        "  index = word_to_index[word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector"
      ],
      "metadata": {
        "id": "9gJe2D27oFAL"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding(\"자연어\", word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wksWvvUZoG4w",
        "outputId": "940defb9-a4f4-4a8b-a153-b54404c53aed"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.케라스(Keras)를 이용한 원-핫 인코딩(One-Hot Encoding)"
      ],
      "metadata": {
        "id": "p56km9-3pJjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스는 원-핫 인코딩을 수행하는 유용한 도구 to_categorical()를 지원"
      ],
      "metadata": {
        "id": "poTUIp8ApL9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
      ],
      "metadata": {
        "id": "0eH8DSfEpO-o"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "print('단어 집합 :',tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG3bmS3LpU5C",
        "outputId": "46ec76f6-09ae-4db6-bf81-08d1347d2079"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texts_to_sequences()를 통해서 이를 정수 시퀀스로 변환가능\n",
        "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYxQ7Z1qj9iN",
        "outputId": "ea91e8ba-55cd-4d41-dca1-4027b09dafbd"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "one_hot = to_categorical(encoded)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdrDkAomkHGg",
        "outputId": "0e3f175e-f08a-4654-f8db-fe7c68697384"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.원-핫 인코딩(One-Hot Encoding)의 한계"
      ],
      "metadata": {
        "id": "VrwR-nR4kOSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 단어의 개수가 늘어날 수록, 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점\n",
        "  - 벡터의 차원이 늘어난다\n",
        "  - 단어 집합의 크기 = 벡터의 차원 수\n",
        "2. 단어의 유사도를 표현하지 못한다는 단점\n",
        "\n",
        "=> 단어의 잠재 의미를 반영하여 다차원 공간에 벡터화 하는 기법 사용\n",
        "1. 카운트 기반의 벡터화 방법인 LSA(잠재 의미 분석), HAL \n",
        "2. 측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText\n",
        "3. 두 가지 방법을 모두 사용하는 방법으로 GloVe"
      ],
      "metadata": {
        "id": "S0MfsuZ3kTF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09) 데이터의 분리(Splitting Data)"
      ],
      "metadata": {
        "id": "oPIq_u1ipAd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지도 학습(Supervised Learning) <br>\n",
        "지도 학습을 위한 데이터 분리 작업"
      ],
      "metadata": {
        "id": "-ULHAUQ3lHHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ERPgaktbl2Ae"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.지도 학습(Supervised Learning)"
      ],
      "metadata": {
        "id": "dpsLBNn-l3FO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정답이 무엇인지 맞춰 하는 '문제'에 해당되는 데이터\n",
        "- 레이블이라고 부르는 '정답'이 적혀있는 데이터\n",
        "\n",
        "><훈련 데이터> <br>\n",
        ">X_train : 문제지 데이터<br>\n",
        ">y_train : 문제지에 대한 정답 데이터.\n",
        "\n",
        "><테스트 데이터> <br>\n",
        ">X_test : 시험지 데이터.<br>\n",
        ">y_test : 시험지에 대한 정답 데이터.\n",
        "\n",
        ">정확도(Accuracy) : 기계가 정답을 얼마나 맞췄는지를 평가"
      ],
      "metadata": {
        "id": "zEBxokdSmD6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.X와 y분리하기"
      ],
      "metadata": {
        "id": "Ch1F3WWGm5nP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.1 zip 함수를 이용하여 분리하기"
      ],
      "metadata": {
        "id": "FQj47R7LnBY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zip()함수 : 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할"
      ],
      "metadata": {
        "id": "ETPeW89RnIQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = zip(['a', 1], ['b', 2], ['c', 3])\n",
        "print('X 데이터 :',X)\n",
        "print('y 데이터 :',y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gkDjQfUnNmr",
        "outputId": "3fea527b-f701-4658-aa7b-ab6a3bdc6d3a"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터 : ('a', 'b', 'c')\n",
            "y 데이터 : (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트의 리스트 또는 행렬 또는 뒤에서 배울 개념인 2D 텐서.\n",
        "sequences = [['a', 1], ['b', 2], ['c', 3]]\n",
        "X, y = zip(*sequences)\n",
        "print('X 데이터 :',X)\n",
        "print('y 데이터 :',y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuvCe68pnPrt",
        "outputId": "c77d498a-3479-49df-ca41-6c50e61abcfe"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터 : ('a', 'b', 'c')\n",
            "y 데이터 : (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.2 데이터프레임을 이용하여 분리하기"
      ],
      "metadata": {
        "id": "YGWz732znjnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [['당신에게 드리는 마지막 혜택!', 1],\n",
        "['내일 뵐 수 있을지 확인 부탁드...', 0],\n",
        "['도연씨. 잘 지내시죠? 오랜만입...', 0],\n",
        "['(광고) AI로 주가를 예측할 수 있다!', 1]]\n",
        "columns = ['메일 본문', '스팸 메일 유무']\n",
        "\n",
        "df = pd.DataFrame(values, columns=columns)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "OW6NTf3qnnOW",
        "outputId": "8bd074a5-9c1e-45f6-b934-ca71ca55fc68"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-412ccfd3-be4c-4ef1-9b9d-d5ac4386cb83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>메일 본문</th>\n",
              "      <th>스팸 메일 유무</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>당신에게 드리는 마지막 혜택!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>내일 뵐 수 있을지 확인 부탁드...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>도연씨. 잘 지내시죠? 오랜만입...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(광고) AI로 주가를 예측할 수 있다!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-412ccfd3-be4c-4ef1-9b9d-d5ac4386cb83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-412ccfd3-be4c-4ef1-9b9d-d5ac4386cb83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-412ccfd3-be4c-4ef1-9b9d-d5ac4386cb83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    메일 본문  스팸 메일 유무\n",
              "0        당신에게 드리는 마지막 혜택!         1\n",
              "1    내일 뵐 수 있을지 확인 부탁드...         0\n",
              "2    도연씨. 잘 지내시죠? 오랜만입...         0\n",
              "3  (광고) AI로 주가를 예측할 수 있다!         1"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['메일 본문']\n",
        "y = df['스팸 메일 유무']"
      ],
      "metadata": {
        "id": "YcW63kTRns1E"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X 데이터 :',X.to_list())\n",
        "print('y 데이터 :',y.to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frg2UlYanuQx",
        "outputId": "291c1839-d78e-4e2d-a718-fed6f061601a"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터 : ['당신에게 드리는 마지막 혜택!', '내일 뵐 수 있을지 확인 부탁드...', '도연씨. 잘 지내시죠? 오랜만입...', '(광고) AI로 주가를 예측할 수 있다!']\n",
            "y 데이터 : [1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Numpy를 이용하여 분리하기"
      ],
      "metadata": {
        "id": "NoASuMMknwbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Numpy의 슬라이싱(slicing)을 사용\n",
        "np_array = np.arange(0,16).reshape((4,4))\n",
        "print('전체 데이터 :')\n",
        "print(np_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv5qUyZInzoE",
        "outputId": "26cf2b25-468a-4b49-ebc8-7e353635d2c4"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 :\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np_array[:, :3]\n",
        "y = np_array[:,3]\n",
        "\n",
        "print('X 데이터 :')\n",
        "print(X)\n",
        "print('y 데이터 :',y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oQ1cdugn4jc",
        "outputId": "fa1ec9de-302f-4f96-de6b-2b68d0181530"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터 :\n",
            "[[ 0  1  2]\n",
            " [ 4  5  6]\n",
            " [ 8  9 10]\n",
            " [12 13 14]]\n",
            "y 데이터 : [ 3  7 11 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.테스트 데이터 분리하기"
      ],
      "metadata": {
        "id": "uSKqDiKPpnjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.1 사이킷 런을 이용하여 분리하기"
      ],
      "metadata": {
        "id": "et0y5CP4p3Rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 테스트와 테스트용 데이터를 쉽게 분리할 수 있게 해주는 train_test_split()를 지원"
      ],
      "metadata": {
        "id": "ufKSifSAqVyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "Yyj72SS2qW3p"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "X : 독립 변수 데이터. (배열이나 데이터프레임)\n",
        "y : 종속 변수 데이터. 레이블 데이터.\n",
        "test_size : 테스트용 데이터 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
        "train_size : 학습용 데이터의 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
        "random_state : 난수 시드\n",
        "````"
      ],
      "metadata": {
        "id": "4ngyfFBDqjGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의로 X와 y 데이터를 생성\n",
        "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
        "\n",
        "print('X 전체 데이터 :')\n",
        "print(X)\n",
        "print('y 전체 데이터 :')\n",
        "print(list(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk997Ofxqqez",
        "outputId": "95b5f6fc-d6f1-4907-f352-0da9a351d4c3"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 전체 데이터 :\n",
            "[[0 1]\n",
            " [2 3]\n",
            " [4 5]\n",
            " [6 7]\n",
            " [8 9]]\n",
            "y 전체 데이터 :\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7:3의 비율로 데이터를 분리 <br>\n",
        "train_test_split()은 기본적으로 데이터의 순서를 섞고나서 훈련 데이터와 테스트 데이터를 분리"
      ],
      "metadata": {
        "id": "u3h-OTO4rAmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7:3의 비율로 훈련 데이터와 테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
      ],
      "metadata": {
        "id": "lmTqyYAlrEEB"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 70%의 비율로 분리\n",
        "print('X 훈련 데이터 :')\n",
        "print(X_train)\n",
        "# 30%의 비율로 분리\n",
        "print('X 테스트 데이터 :')\n",
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhWc3SBGrLfd",
        "outputId": "fec6da38-97eb-4c24-c7fd-df56bf478b85"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 훈련 데이터 :\n",
            "[[2 3]\n",
            " [4 5]\n",
            " [6 7]]\n",
            "X 테스트 데이터 :\n",
            "[[8 9]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y 훈련 데이터 :')\n",
        "print(y_train)\n",
        "print('y 테스트 데이터 :')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv0ixVWIrTz3",
        "outputId": "0bfef728-b762-4aa6-80fb-86acfbb6fac3"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y 훈련 데이터 :\n",
            "[1, 2, 3]\n",
            "y 테스트 데이터 :\n",
            "[4, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state의 값을 변경\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "print('y 훈련 데이터 :')\n",
        "print(y_train)\n",
        "print('y 테스트 데이터 :')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H-d6egerXFk",
        "outputId": "2e88b876-1feb-4785-fde8-09f244aa75df"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y 훈련 데이터 :\n",
            "[4, 0, 3]\n",
            "y 테스트 데이터 :\n",
            "[2, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state을 이전의 값이었던 1234로 변경\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
        "\n",
        "print('y 훈련 데이터 :')\n",
        "print(y_train)\n",
        "print('y 테스트 데이터 :')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVHWYA5rdc0",
        "outputId": "3983b08e-a448-4be1-c22f-cb1f737a098f"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y 훈련 데이터 :\n",
            "[1, 2, 3]\n",
            "y 테스트 데이터 :\n",
            "[4, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 수동으로 분리하기"
      ],
      "metadata": {
        "id": "36i0JHQ2rhun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습을 위해 임의로 X와 y가 이미 분리 된 데이터를 생성\n",
        "X, y = np.arange(0,24).reshape((12,2)), range(12)\n",
        "\n",
        "print('X 전체 데이터 :')\n",
        "print(X)\n",
        "print('y 전체 데이터 :')\n",
        "print(list(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L233V1Zrmft",
        "outputId": "b41a05a1-f8ae-4b3e-f4e1-03827982d3d0"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 전체 데이터 :\n",
            "[[ 0  1]\n",
            " [ 2  3]\n",
            " [ 4  5]\n",
            " [ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]\n",
            " [12 13]\n",
            " [14 15]\n",
            " [16 17]\n",
            " [18 19]\n",
            " [20 21]\n",
            " [22 23]]\n",
            "y 전체 데이터 :\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_train = int(len(X) * 0.8) # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다.\n",
        "num_of_test = int(len(X) - num_of_train) # 전체 길이에서 80%에 해당하는 길이를 뺀다.\n",
        "print('훈련 데이터의 크기 :',num_of_train)\n",
        "print('테스트 데이터의 크기 :',num_of_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3X6bforoVG",
        "outputId": "fc92eff1-9828-4fd6-c415-f6203c7e41a3"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : 9\n",
            "테스트 데이터의 크기 : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어느 한 쪽을 먼저 계산하고 그 값만큼 제외하는 방식으로 계산 <br>\n",
        "데이터를 나눌 때는 num_of_train와 같이 하나의 변수만 사용하면 데이터의 누락을 방지할 수 있습니다."
      ],
      "metadata": {
        "id": "l1UucG5Xrsqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
        "y_test = y[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
        "X_train = X[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
        "y_train = y[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장"
      ],
      "metadata": {
        "id": "MydlXcH1ruLV"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X 테스트 데이터 :')\n",
        "print(X_test)\n",
        "print('y 테스트 데이터 :')\n",
        "print(list(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgw2zxWtr3HT",
        "outputId": "ce2e89af-2aa7-4fee-c5e7-a6d2039a7ade"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 테스트 데이터 :\n",
            "[[18 19]\n",
            " [20 21]\n",
            " [22 23]]\n",
            "y 테스트 데이터 :\n",
            "[9, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split()과 다른 점 : 데이터가 섞이지 않은 채 어느 지점에서 데이터를 앞과 뒤로 분리했다는 점"
      ],
      "metadata": {
        "id": "yyTrfua-r6kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) 한국어 전처리 패키지(Text Preprocessing Tools for Korean Text)"
      ],
      "metadata": {
        "id": "q0cnqSNVpCUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.PyKoSpacing"
      ],
      "metadata": {
        "id": "5dq7SU3ssD8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "metadata": {
        "id": "-ku-1H0WsbKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyKoSpacing은 띄어쓰기가 되어있지 않은 문장을 띄어쓰기를 한 문장으로 변환해주는 패키지 <br>\n",
        "대용량 코퍼스를 학습하여 만들어진 띄어쓰기 딥 러닝 모델로 준수한 성능을 가지고 있다."
      ],
      "metadata": {
        "id": "VwVFgfDpwY6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'"
      ],
      "metadata": {
        "id": "o0CdMTs7tP4p"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
        "print(new_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttMnvRfbtSJ2",
        "outputId": "a64d084e-81c1-40a7-b579-badc1044a4b4"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pykospacing import Spacing\n",
        "spacing = Spacing()\n",
        "kospacing_sent = spacing(new_sent) \n",
        "\n",
        "print(sent)\n",
        "print(kospacing_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6y_509YtUFn",
        "outputId": "f938a83b-53a4-4369-8771-6393bc2f0116"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
            "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Py-Hanspell"
      ],
      "metadata": {
        "id": "QPnbcKPMsy03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2-wNdPhs5Zg",
        "outputId": "424d6f7f-be60-4184-b0bc-976c38f726f0"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-9t__93kn\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-9t__93kn\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4868 sha256=280675a3e1392a771850df4ee42bb1923b4d814794ebede3855cdf1bca103baf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iirep5we/wheels/ab/f5/7b/d4124bb329c905301baed80e2ae45aa14e824f62ebc3ec2cc4\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Py-Hanspell은 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지"
      ],
      "metadata": {
        "id": "dfi4nOf7wygm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hanspell import spell_checker\n",
        "\n",
        "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
        "spelled_sent = spell_checker.check(sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo-WW1l6wz9R",
        "outputId": "23af9125-c963-46ae-8863-80c5af54e4f5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기 또한 보정"
      ],
      "metadata": {
        "id": "LUAQEJKzxCbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spelled_sent = spell_checker.check(new_sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)\n",
        "print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgtsDMK6xDpS",
        "outputId": "c45000da-a3ab-4ba2-8d40-bde9ace5bb77"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는 극 중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연제(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
            "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.SOYNLP를 이용한 단어 토큰화"
      ],
      "metadata": {
        "id": "mSonnVw3sv3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- soynlp는 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저 <br>\n",
        "- 비지도 학습으로 단어 토큰화를 한다는 특징 <br>\n",
        "- soynlp 단어 토크나이저는 내부적으로 단어 점수 표로 동작\n",
        "- 응집 확률(cohesion probability)과 브랜칭 엔트로피(branching entropy)를 활용"
      ],
      "metadata": {
        "id": "3Y3sYfQCxeD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install soynlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eKKATM4xgDS",
        "outputId": "fcf555ba-00e9-43dd-caa5-b520312e6e96"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 416 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 신조어 문제"
      ],
      "metadata": {
        "id": "E32S5EYhx1QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존의 형태소 분석기는 신조어나 형태소 분석기에 등록되지 않은 단어 같은 경우에는 제대로 구분하지 못하는 단점"
      ],
      "metadata": {
        "id": "7AvGq2QFx6Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt()\n",
        "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AztdEgJx7_a",
        "outputId": "601007c6-7f5f-4a0e-9820-a84ed62ba9ab"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 데이터에서 특정 문자 시퀀스가 함께 자주 등장하는 빈도가 높고, <br>\n",
        "앞 뒤로 조사 또는 완전히 다른 단어가 등장하는 것을 고려해서 해당 문자 시퀀스를 형태소라고 판단하는 단어 토크나이저"
      ],
      "metadata": {
        "id": "5OFV9SzPyFF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 학습하기"
      ],
      "metadata": {
        "id": "1y5xuDxayLCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "soynlp는 기본적으로 학습에 기반한 토크나이저"
      ],
      "metadata": {
        "id": "RajrDkR-yUNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from soynlp import DoublespaceLineCorpus\n",
        "from soynlp.word import WordExtractor"
      ],
      "metadata": {
        "id": "mJSdzy7XyVgx"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 필요한 한국어 문서를 다운로드\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqCM6mCQyW6E",
        "outputId": "ed5fad8d-1f34-4d89-ad84-bd2315afcc75"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2016-10-20.txt', <http.client.HTTPMessage at 0x7f9c458fc510>)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터를 다수의 문서로 분리\n",
        "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9BUkqDbybnN",
        "outputId": "149d5f8a-ce75-4ac0-cbd3-1f79c08f6449"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30091"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for document in corpus:\n",
        "  if len(document) > 0:\n",
        "    print(document)\n",
        "    i = i+1\n",
        "  if i == 3:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVQK3US8ye2-",
        "outputId": "46a6ff20-5024-49d0-96f5-f018b5a6f4dd"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19  1990  52 1 22\n",
            "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
            "테헤란 연합뉴스 강훈상 특파원 이용 승객수 기준 세계 최대 공항인 아랍에미리트 두바이국제공항은 19일 현지시간 이 공항을 이륙하는 모든 항공기의 탑승객은 삼성전자의 갤럭시노트7을 휴대하면 안 된다고 밝혔다  두바이국제공항은 여러 항공 관련 기구의 권고에 따라 안전성에 우려가 있는 스마트폰 갤럭시노트7을 휴대하고 비행기를 타면 안 된다 며 탑승 전 검색 중 발견되면 압수할 계획 이라고 발표했다  공항 측은 갤럭시노트7의 배터리가 폭발 우려가 제기된 만큼 이 제품을 갖고 공항 안으로 들어오지 말라고 이용객에 당부했다  이런 조치는 두바이국제공항 뿐 아니라 신공항인 두바이월드센터에도 적용된다  배터리 폭발문제로 회수된 갤럭시노트7 연합뉴스자료사진\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존의 KoNLPy에서 제공하는 형태소 분석기들과는 달리 학습 과정을 거쳐야 한다. <br>\n",
        "전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피 단어 점수표를 만드는 과정 <br>\n",
        "WordExtractor.extract()를 통해서 전체 코퍼스에 대해 단어 점수표를 계산"
      ],
      "metadata": {
        "id": "J_eD6S5wylJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn2Y8GhEyt2j",
        "outputId": "2f091c4a-8f00-4407-8281-45221b29bd3f"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training was done. used memory 5.119 Gb\n",
            "all cohesion probabilities was computed. # words = 223348\n",
            "all branching entropies was computed # words = 361598\n",
            "all accessor variety was computed # words = 361598\n",
            "CPU times: user 1min 53s, sys: 938 ms, total: 1min 54s\n",
            "Wall time: 1min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 SOYNLP의 응집 확률(cohesion probability)"
      ],
      "metadata": {
        "id": "HOYFDsvGyPDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응집 확률은 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도 <br>\n",
        ">문자열을 문자 단위로 분리하여 내부 문자열을 만드는 과정에서 <br>\n",
        ">왼쪽부터 순서대로 문자를 추가하면서 각 문자열이 주어졌을 때<br>\n",
        ">그 다음 문자가 나올 확률을 계산하여 누적곱을 한 값\n",
        "- 이 값이 높을수록 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성이 높다\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "EmqQ-9hey6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_score_table[\"반포한\"].cohesion_forward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0_Ye7VizwbX",
        "outputId": "b7d4c6c1-1998-497e-c190-746f6cf5add3"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08838002913645132"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_score_table[\"반포한강\"].cohesion_forward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwyCBowV0FHR",
        "outputId": "895c2b0b-c238-4193-8b23-5d3f668ea70c"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19841268168224552"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_score_table[\"반포한강공\"].cohesion_forward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgpOCr3S0HcK",
        "outputId": "baf5da7c-3a29-49d4-baa0-442ff872a57c"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2972877884078849"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 응집확률이 제일 높다\n",
        "word_score_table[\"반포한강공원\"].cohesion_forward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIuJS8qY0Id1",
        "outputId": "c20d75be-385e-410c-d06b-642f57c03f7d"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37891487632839754"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_score_table[\"반포한강공원에\"].cohesion_forward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UgdgKHU0NbE",
        "outputId": "7c469faf-18a0-4896-8c06-7e886d6b5f06"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33492963377557666"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 단어로 판단하기에 가장 적합한 문자열은 '반포한강공원'이라고 볼 수 있다."
      ],
      "metadata": {
        "id": "RDTr2lKM0PNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4 SOYNLP의 브랜칭 엔트로피(branching entropy)"
      ],
      "metadata": {
        "id": "-uYlF2qPyRVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Branching Entropy는 확률 분포의 엔트로피값을 사용 <br>\n",
        "주어진 문자열에서 얼마나 다음 문자가 등장할 수 있는지를 판단하는 척도 <br>\n",
        "하나의 완성된 단어에 가까워질수록 문맥으로 인해 점점 정확히 예측할 수 있게 되면서 점점 줄어드는 양상을 보인다"
      ],
      "metadata": {
        "id": "fq9KFKUa0XyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '디스' 다음에는 다양한 문자가 올 수 있으니까 1.63\n",
        "word_score_table[\"디스\"].right_branching_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezD1b51G011D",
        "outputId": "076b10a7-4464-4e1f-cf45-07ba5ab1f3f5"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6371694761537934"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '디스플'이라는 문자열 다음에는 다음 문자로 '레'가 오는 것이 너무나 명백\n",
        "word_score_table[\"디스플\"].right_branching_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcNzYDZX03ES",
        "outputId": "d78dd31f-74e3-439f-c72c-bc06150de2b0"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_score_table[\"디스플레\"].right_branching_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q5A92PS1IHz",
        "outputId": "c33f0a9d-d243-4303-d934-418bb3033450"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '디스플레이'라는 문자 시퀀스 다음에는 조사나 다른 단어와 같은 다양한 경우가 있을 수 있기 때문\n",
        "word_score_table[\"디스플레이\"].right_branching_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXIYtnS_1JOZ",
        "outputId": "4776251d-eb51-4349-a3df-e8dc97bf9570"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1400392861792916"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 단어가 끝나면 그 경계 부분부터 다시 브랜칭 엔트로피 값이 증가<br>\n",
        "=> 이 값으로 단어를 판단하는 것이 가능"
      ],
      "metadata": {
        "id": "XJRclw6j1Wqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5 SOYNLP의 L tokenizer"
      ],
      "metadata": {
        "id": "k8SuZzaM0U8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L 토큰 + R 토큰의 형식 ('공원에' = '공원 + 에') <br>\n",
        "분리 기준을 점수가 가장 높은 L 토큰을 찾아내는 원리"
      ],
      "metadata": {
        "id": "dSkSpW8-1Ctn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
        "l_tokenizer = LTokenizer(scores=scores)\n",
        "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQgXSd_B1jBX",
        "outputId": "a1820910-d221-42dd-9b7d-47e8bb39b84e"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6 최대 점수 토크나이저"
      ],
      "metadata": {
        "id": "LiDDnfF-09WS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저"
      ],
      "metadata": {
        "id": "-cZ_A4VP1qcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과\n",
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "\n",
        "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
        "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx2E4SLP1wN0",
        "outputId": "9f5cfd67-38d3-4145-85b6-b57272ad5aeb"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.SOYNLP를 이용한 반복되는 문자 정제"
      ],
      "metadata": {
        "id": "T-VWo5_Jso2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㅋㅋ, ㅋㅋㅋ, ㅋㅋㅋㅋ와 같은 경우를 모두 서로 다른 단어로 처리하는 것은 불필요 <br>\n",
        "반복되는 것은 하나로 정규화시킴"
      ],
      "metadata": {
        "id": "8LUrLWJc13Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from soynlp.normalizer import *\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95lNxErc19OG",
        "outputId": "8367d2dc-42ee-468b-9433-8eb62a4173a0"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
            "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
            "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
            "아ㅋㅋ영화존잼쓰ㅠㅠ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하핫', num_repeats=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ubwI2tX2AHa",
        "outputId": "e9acaf4c-a6a0-4fda-833b-3a0ab3ad7f2a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "와하하핫\n",
            "와하하핫\n",
            "와하하핫\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Customized KoNLPy"
      ],
      "metadata": {
        "id": "Ypl9z7w6skht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "형태소 분석기를 사용해서 단어 토큰화\n",
        "```\n",
        "형태소 분석 입력 : '은경이는 사무실로 갔습니다.'\n",
        "형태소 분석 결과 : ['은', '경이', '는', '사무실', '로', '갔습니다', '.']\n",
        "```\n",
        "형태소 분석기에 사용자 사전을 추가해줄 수 있다."
      ],
      "metadata": {
        "id": "3XxILANf2FGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install customized_konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUbs6UBc7LO5",
        "outputId": "71881767-9db7-4849-8c9e-65e128ad1f27"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting customized_konlpy\n",
            "  Downloading customized_konlpy-0.0.64-py3-none-any.whl (881 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 389 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 419 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 450 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 481 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 512 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 542 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 563 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 573 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 593 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 604 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 624 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 655 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 665 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 686 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 696 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 727 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 747 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 757 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 778 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 788 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 808 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 819 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 829 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 839 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 849 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 860 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 870 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 880 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 881 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jpype1>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from customized_konlpy) (1.3.0)\n",
            "Requirement already satisfied: konlpy>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from customized_konlpy) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from Jpype1>=0.6.1->customized_konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (1.19.5)\n",
            "Installing collected packages: customized-konlpy\n",
            "Successfully installed customized-konlpy-0.0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "customized_konlpy에서 제공하는 형태소 분석기 Twitter"
      ],
      "metadata": {
        "id": "9ghcb2Jc7aN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ckonlpy.tag import Twitter\n",
        "twitter = Twitter()\n",
        "twitter.morphs('은경이는 사무실로 갔습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTFhZcR57bgf",
        "outputId": "b2f42bc5-51b1-46c2-d01c-869b250189db"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Twitter에 add_dictionary('단어', '품사')와 같은 형식으로 사전 추가를 해줄 수 있다"
      ],
      "metadata": {
        "id": "6n_KyIUB7eCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.add_dictionary('은경이', 'Noun')"
      ],
      "metadata": {
        "id": "cKVf3uSl7fxy"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'은경이'라는 단어가 제대로 하나의 토큰으로 인식\n",
        "twitter.morphs('은경이는 사무실로 갔습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN87Q2PE7igL",
        "outputId": "b038a722-8207-437e-f7ec-6c2e4e8e7127"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['은경이', '는', '사무실', '로', '갔습니다', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    }
  ]
}